{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate MRI images of different contrast levels using cyclic GANs</h3>\n",
    "<br>\n",
    "<p><b>Capstone Summary : </b> Medical misdiagnosis is an extremely serious problem, but it also happens far too frequently. Since interpreting imaging methods in the medical profession is not a straightforward binary process (Normal or Abnormal), it is necessary to have a radiologist's opinion. Even so, it's possible for one radiologist to detect something another misses. Conflicting information might result from this, making it challenging to appropriately suggest therapy options to the patient.\n",
    "\n",
    "\n",
    "The diagnosis of an MRI (Magnetic Resonance Imaging) is one of the challenging challenges in medical imaging. The radiologist may occasionally require several imaging modalities to interpret the scan, which can significantly improve diagnosis accuracy by giving practitioners a more complete knowledge.\n",
    "\n",
    "But getting access to various imaging is expensive and complex. We can employ style transfer to create artificial MRI images of various contrast levels from pre-existing MRI scans with the use of deep learning. With the use of a second image, this will aid in providing a better diagnosis.\n",
    "\n",
    "To transfer the style of one MRI image to another in this capstone and improve understanding of the scanned image, CycleGAN will be used. You can convert T1 weighted MRI scans into T2 weighted pictures using GANs, and vice versa.\n",
    "</p>\n",
    "<br>\n",
    "<p><b>Project Statement : </b>To develop a generative adversarial model (modified U-Net) that can create synthetic MRI pictures with various contrast levels from existing MRI scans</p>\n",
    "\n",
    "<p><b>Dataset Used : </b>MRI+T1_T2+Dataset</p>\n",
    "\n",
    "<p>NOTE: Since this is an unpaired dataset, there is no relationship whatsoever between the T1 and T2 MRI images that are part of it.</p>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.49.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\karan\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\karan\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.27.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: keras in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (2.13.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karan\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karan\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (4.37.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karan\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (0.19.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (1.23.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (2.19.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karan\\appdata\\roaming\\python\\python310\\site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (2.8.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: imageio in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (2.19.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from imageio) (1.23.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\karan\\anaconda3\\envs\\gpu\\lib\\site-packages (from imageio) (9.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement glob (from versions: none)\n",
      "ERROR: No matching distribution found for glob\n"
     ]
    }
   ],
   "source": [
    "#Import all the required libraries to python \n",
    "!pip install tensorflow \n",
    "!pip install keras\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "!pip install imageio\n",
    "!pip install glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the required libraries\n",
    "\n",
    "# Data Science \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning \n",
    "import tensorflow as tf\n",
    "\n",
    "# Image Preprocess \n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "# OS Navigation \n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from sys import platform\n",
    "\n",
    "# Ignore Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# notebook imports \n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy : 1.23.3\n",
      "matplotlib : 3.5.2\n",
      "tensorflow : 2.13.0\n",
      "skimage : 0.19.2\n",
      "imageio : 2.19.3\n",
      "PIL : 9.2.0\n",
      "sys : 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Printing all the version of require libraries \n",
    "print(\"Numpy : {}\" .format(np.__version__))\n",
    "print(\"matplotlib : {}\" .format(matplotlib.__version__))\n",
    "print(\"tensorflow : {}\" .format(tf.__version__))\n",
    "print(\"skimage : {}\" .format(skimage.__version__))\n",
    "print(\"imageio : {}\" .format(imageio.__version__))\n",
    "print(\"PIL : {}\" .format(PIL.__version__))\n",
    "print(\"sys : {}\" .format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the module is present in sys.modules \n",
    "def is_imported(module, sys_imported = \"sys\" in dir()):\n",
    "    \"\"\"\n",
    "    This function is responsible for checking if a required module is present in the enviorment or not \n",
    "    :params module: (str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type(module) == str:\n",
    "            if sys_imported:\n",
    "                return module in sys.modules\n",
    "            else:\n",
    "                raise ModuleNotFoundError(\"Module Missing sys, please import sys module to the enviorment\")\n",
    "        else:\n",
    "            raise TypeError(\"Expected input as String and not any other type\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Operation could not be started due to  {} : {}\" .format(type(e).__name__, e.args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the images & create two seperate datasets. The input shape for image should be (256, 256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading and Path Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dynamic path \n",
    "\n",
    "# Current platform\n",
    "current_platform = sys.platform\n",
    "\n",
    "# path for current working directory \n",
    "path = os.getcwd()\n",
    "\n",
    "# Replace \"/\" and \"\\\"\n",
    "if current_platform == \"linux\" or current_platform == \"linux2\": # Linux\n",
    "    path.replace(\"/\", os.sep)\n",
    "elif current_platform == \"darwin\": # MacOS\n",
    "    path.replace(\"/\", os.sep)\n",
    "elif current_platform == \"win32\": # Windows\n",
    "    path.replace(\"\\\\\", os.sep)\n",
    "else:\n",
    "    path.replace(\"/\", os.sep)\n",
    "\n",
    "# Storing Paths\n",
    "t1_path = os.path.join(path, \"MRI+T1_T2+Dataset\"+os.sep+\"Tr1\"+os.sep+\"TrainT1\")\n",
    "t2_path = os.path.join(path, \"MRI+T1_T2+Dataset\"+os.sep+\"Tr2\"+os.sep+\"TrainT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset from image directory\n",
    "tr1 = t1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset from image directory\n",
    "tr2 = t2_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing images in the location \"TrainT1\" and \"TrainT2\"\n",
    "t1_images = os.listdir(t1_path)\n",
    "t2_images = os.listdir(t2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Image #11.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valiadting the filename extension\n",
    "t1_images[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the image in Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Numpy array of the image\n",
    "imageio.imread(t1_path+ os.sep +t1_images[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the images to from the folder to list of numpy array \n",
    "def image_extractor(folder_path, folder_image_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to convert all the images given in a folder with the respective path to it to list of \n",
    "    :param ospath: loaction to the folder \n",
    "    :param imgfolder: target folder name\n",
    "    :return: numpy arrray of images \n",
    "    \"\"\"\n",
    "    # Checking if numpy is imported as os is a default module \n",
    "    if is_imported(\"numpy\"):\n",
    "        # Checking if imageio is imported as os is a default module \n",
    "        if is_imported(\"imageio\"):\n",
    "\n",
    "            # Stroing images in a list     \n",
    "            img_lst = []\n",
    "\n",
    "            # Appending all the images to the list     \n",
    "            for file in folder_image_list:\n",
    "                read_img = imageio.imread(folder_path+ '/' + file)\n",
    "                img_lst.append(read_img)\n",
    "\n",
    "            # converts list to a numpy array\n",
    "            final_array = np.asarray(img_lst)\n",
    "\n",
    "            return final_array\n",
    "\n",
    "        else:\n",
    "            raise ImportError(\"Missing imageio module, Please Import the imageio module\")\n",
    "    else:\n",
    "        raise ImportError(\"Missing numpy module, Please Import the numpy module\")\n",
    "    \n",
    "\n",
    "\n",
    "# Data loading\n",
    "t1 = image_extractor(t1_path, t1_images)\n",
    "t2 = image_extractor(t2_path, t2_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 Shape : (43, 217, 181)\n",
      "T2 Shape: (46, 217, 181)\n",
      "In T1 each image is (217, 181) dimention\n",
      "In T2 each image is (217, 181) dimention\n",
      "T1 Folder has 43 images\n",
      "T1 Folder has 46 images\n",
      "Total Number of images in Dataset : 89\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape \n",
    "print('T1 Shape : {}' .format(t1.shape))\n",
    "print('T2 Shape: {}' .format(t2.shape))\n",
    "\n",
    "# Printing the dimentions of images\n",
    "print('In T1 each image is {} dimention' .format(t1.shape[1:]))\n",
    "print('In T2 each image is {} dimention' .format(t2.shape[1:]))\n",
    "\n",
    "# Printing the Number of images in each folder \n",
    "print('T1 Folder has {} images' .format(t1.shape[0]))\n",
    "print('T1 Folder has {} images' .format(t2.shape[0]))\n",
    "\n",
    "# Adding all the rows of t1 and t2 \n",
    "print('Total Number of images in Dataset : {}' .format(t1.shape[0]+t2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:yellow\"><b>Observation : </b>We can Observe that the number of images in the dataset is less compared to usual training dataset, Hence we know the ability of the Generated Adversal Networks to generate images of unpaired images learning the features in every time it train therefore we can tradeoff the data augmentation with more number of epochs</p>\n",
    "\n",
    "<p>The dataset consist of only 89 images which are of dimentions 217*181</p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
